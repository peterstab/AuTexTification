In this project, we focused on distinguishing between texts generated by humans and those produced by linguistic models. 
We worked with a dataset comprising a diverse collection of texts from both sources. 
The core objective was to develop a robust binary classification system to accurately identify the origin of each text.
We employed a variety of machine learning techniques, ranging from traditional models to advanced transformers like BERT. 
The process involved extracting numerous linguistic features to train and evaluate the performance of these models.

Additionally, we included a 6-class classification, to identify the model that produced previous texts labelled as model generated.

Code has comments that make an easier interpreatation
